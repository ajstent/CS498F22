This notebook and accompanying dataset illustrate how you might look at, clean up and normalize your data.

Some caveats:
* This was developed for CS252, where students work directly in numpy. If you load the BTM data with numpy, you will have to convert all the variables to floats. Feel free to "pop up a level" and load the BTM data directly in pandas.
* You will want to do a spatial mapping of the data. If you load the data in pandas, you can use plotly for this.

Those caveats notwithstanding, we hope that over the coming week you will be able to:
* load
* inspect / clean / normalize
* plot (and map)
* cluster
* do basic modeling
of this data set.

Feel free to do this in your teams! And to contribute your noteboks to git!

Questions for you to consider:
* Which variables are highly correlated (if any)?
* Are any variables much larger (or smaller) in summary statistics than others? How will you deal with this?
* How many independent variables are there? Which will be the dependent variable?
* Are there missing or anomalous variable values?
* What do you *see* in the data?
